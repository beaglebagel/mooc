{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "\n",
    "** Basic NLP Pipeline**\n",
    "   - (U)nderstanding and (G)eneration\n",
    "   - Langauge -> (U) -> Computer -> (G) -> Language\n",
    "\n",
    "** Vocabulary**\n",
    "   - NLP(Natural Language Processing)\n",
    "   - CL(Computational Linguistics)\n",
    "   - IR(Information Retrieval)\n",
    "   - SP(Speech Processing)\n",
    "   - HLP(Human Language Technology)\n",
    "   - NLE(Natural Langauge Engineering)\n",
    "   - ML(Machine Learning)\n",
    "\n",
    "** Reasons for NLP Difficutiles**\n",
    "   - Syntax vs Semantics\n",
    "       - *Little a has Mary lamb. -> Syntactically incorrect.\n",
    "       - ?Colorless green ideas sleep furiously -> Syntactically well formed, Semantically(meaning) incorrect.\n",
    "   - Ambiguous words\n",
    "       - meaning: e.g, ball, board, plant\n",
    "       - part of speech: e.g, fly, rent, tape\n",
    "       - (multiple) pronunciation: e.g, address, resent, entrance, number, uninized\n",
    "       - Noun-noun phrases: (XY)Z vs X(YZ). e.g, science fiction writer, customer service representatives, state chess tournament.\n",
    "   - Types of ambibuity\n",
    "       - Morphologica: e.g, Joe is quite impossible. Joe is quite important.\n",
    "       - Phonetic: e.g, Joe's finger got number.\n",
    "       - Part of speech: e.g, Joe won the first round.\n",
    "       - Syntactic: e.g, Call joe a taxi.\n",
    "       - Pp attachment: e.g, Joe ate pizza with a fork.\n",
    "       - Sense: e.g, Joe took the bar exam.\n",
    "       - Modality: e.g, Joe may win the lottery.\n",
    "       - Subjectivity: e.g, Joe believes that stocks will rise.\n",
    "       - Cc(Coordinating Conjunction) attachement: e.g, Joe likes ripe apples **`and`** pears.\n",
    "       - Negation: e.g, Joe likes his pizza with no cheese and tomatoes.\n",
    "       - Referential: e.g, Joe yelled at Mike. He had broken the bike. (who's he?)\n",
    "       - Reflextive: e.g, John bought him a present.\n",
    "       - Ellipsis and parallelism: e.g, Joe gave Mike a beer and Jeremy a glass of wine.\n",
    "       - Metonymy: e.g, Boston called and left a message for Joe. (Boston not as city)\n",
    "       - Non-standard slang, novel words and usages: e.g, A360, spam, chillax\n",
    "       - Inconsistencie: e.g, pet spray, pet llama\n",
    "       - Typoes/Grammatical errors: e.g, Reciept, should of\n",
    "       - Parsing problems: e.g, Cup holder, Federal Reserve Board Chairman\n",
    "       - Complex sentences\n",
    "       - Counterfactual sentences: e.g, If you were ~\n",
    "       - Humor and sarcasm\n",
    "       - Implicature/inference/world knowledge: e,g I was late because my car broke down.(I imples, I own the car, car can break down..)\n",
    "       - Semantics vs. Pragmatics: e.g, Do you know the time?\n",
    "       - Synonyms and Paraphrases: e.g, The S&P500 **climbed** ~, it's **best close** since ~.\n",
    "\n",
    "**Linguistics knowledge**\n",
    "   - Constituents: e.g, Children eat pizza, They eat pizza.\n",
    "   - Collocations: e.g, Strong beer - *powerful beer, Big sister - *large sister.\n",
    "   - Knowledge about language:\n",
    "       - Phonetics and phonology - study of sounds\n",
    "       - Morphology: study of word components\n",
    "       - Syntax: study of sentence and phrases structure\n",
    "       - Lexical Sematics: study of the meaning of words\n",
    "       - Compositional semantics: how to combine words\n",
    "       - Pragmatics: how to accomplish goals\n",
    "       - Discourse conventios: how to deal with units larger than utterances\n",
    "\n",
    "**Theoretical Computer Science**\n",
    "   - Automata\n",
    "       - Deterministic and non-deterministic finite-state automata\n",
    "       - Push-down automata\n",
    "   - Grammars\n",
    "       - Regular grammars\n",
    "       - Context-free grammars\n",
    "       - Context-sensitive grammars\n",
    "   - Complexity\n",
    "   - Algorithms: Dynamic programming\n",
    "\n",
    "**Mathematical and Computational Tools**\n",
    "   - Language models\n",
    "   - Estimation methods\n",
    "   - Context-free grammars(CFG)\n",
    "   - Hidden Markov Models(HMM)\n",
    "   - Conditional Random Fields(CRF)\n",
    "   - Generative/discriminative models\n",
    "   - Maximum entroy models\n",
    "\n",
    "**Statistical Techniques**\n",
    "   - Vector space representation for WSD\n",
    "   - Noisy channel models for MT\n",
    "   - Graph-based Random walk methods for sentiment analysis\n",
    "\n",
    "** Artificial Intelligence**\n",
    "   - Logic, Agent, Planning, Constraint Satisfaction, Machine Learning.\n",
    "\n",
    "**`Cognates`** : a term in linguistic referring to words with common ancestry. (night, nuit, Nacht etc..)\n",
    "\n",
    "**Diversity of Languages**\n",
    "   - Articles: e.g, Russians don't have articles like *the, a* etc.\n",
    "   - Cases: e.g, *(Puer puellam vexat)*: Puer(Boy) is noun or normative, puellam(Girl) is subject, vexat(annoy) is verb. In latin the meaning of the words is retained regardless of word orders as long as verb comes the latest.\n",
    "   - Sound systems: e.g, Glottal stop - 'uh-oh'\n",
    "   - Social status: e.g, otousan, chichi\n",
    "   - Kinships: ways to refer to relatives.\n",
    "   \n",
    "**Languages Universals**\n",
    "   - unconditional: e.g, all languages have both verbs and nouns, all spoken languages have both consonants and vowels.\n",
    "   - conditional: \n",
    "       - e.g, if both subjects/objects are nouns, much more common to have subject preceding object.\n",
    "       - if inflection then derivation. e.g, inflection: sleep -> sleeps, derivation: drink -> drinkable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "** Parts of Speech **\n",
    "   - Syntactic Categories\n",
    "      - Substitution test:\n",
    "         - Nathalie likes {black, Persian, tabby, small} cats.\n",
    "         - Single words that can be in same position. `Category: Adjective`\n",
    "      - Open(lexical) category:\n",
    "         - Can have words added as time goes: (e.g, No-fly-zone, twerk)\n",
    "      - Closed(functional) category:\n",
    "         - determiners or articles and prepositions(e.g, the, in)\n",
    "   - Parts of Speech\n",
    "      - Eight general types\n",
    "          - Noun (e.g, dog, tree, computer idea..)\n",
    "          - Pronoun (e.g, she, ourselves, mine..)\n",
    "          - Determiners\n",
    "              - Articles: (e.g, the, a)\n",
    "              - Demonstratives: (e.g, this, that)\n",
    "          - Adjective - describes properties\n",
    "          - Verb - actions, activities and states (e.g, throw, walk, have)\n",
    "              - intransitive (no direct object): The dog sleeps\n",
    "              - transitive (has direct object): The dog chased the cat.\n",
    "              - ditransitive (takes two objects): Mary gave the dog a bone.\n",
    "          - Adverb - happily, here, never\n",
    "          - Prepopsitions (e.g, of, through, in)\n",
    "          - Particles\n",
    "              - Phrasal verbs(e.g, the plane took off, take it off)\n",
    "          - Particles vs. Prepositions:\n",
    "              - She ran up a hill > Up a hill she ran (Preposition)\n",
    "              - She ran up a bill x Up a bill she ran (Particle)\n",
    "          - Coordinating conjunctions\n",
    "              - connects simliar parts of the sentence (e.g, and, or, but)\n",
    "          - Subordinating conjunctions\n",
    "              - connects different portions of the sentence that are not equal (e.g, if, because, that, although)\n",
    "          - Interjections (e.g, Ouch!)\n",
    "   - Parts of Speech Tags\n",
    "       - NN - singular noun\n",
    "       - IN - preposition\n",
    "       - AT - article\n",
    "       - NP - proper noun\n",
    "       - JJ - adjective\n",
    "       - , - comma\n",
    "       - NNS - plural noun\n",
    "       - CC - conjunction\n",
    "       - RB - adverb\n",
    "       - VB - un-inflected verb\n",
    "       - VBN - verb + en (talen, looked (passive, perfect))\n",
    "       - VBD - verb + ed (took, looked (past tense))\n",
    "       - CS - subordinating conjunction\n",
    "\n",
    "** Morphology and Lexicon **\n",
    "   - Mental Lexicon - our mental process of interpreting texts (meaning? part of speech? pronunciation?)\n",
    "   - Derivational Morphology - how different forms of words are created from other words by adding different `affixes(prefix, suffix)`. (e.g, JJ <- V(drink) + able)\n",
    "   - Morphemes - the morphemes of words are individual units of morphological meaning.\n",
    "   - Inflectional Morphology - Tense, number, person, mood, aspect\n",
    "   - Morphological Analysis - takes a word and converts to morphological representation.\n",
    "       - sleeps = sleep(infinitive) + V(verb) + 3P(third person) + SG(singular)\n",
    "       - done = do(infinitive) + V(verb) + PP(past participle)\n",
    "\n",
    "** Semantics **\n",
    "   - Study of the meaning of words and sentences\n",
    "   - Lexical Semantics - meaning of individual words, relationship between the word pairs.\n",
    "   - Compositional Semantics - how to understand the meaning of a sentence based on the meaning of it's components.\n",
    "   \n",
    "** Pragmatics **\n",
    "\n",
    "** Text Similarity **\n",
    "   - Types of text similarity\n",
    "       - Morphological (e.g, respect - respectful)\n",
    "       - Spelling (e.g, theater - theatre)\n",
    "       - Synonymy - words with simliar meaning (e.g, talkative - chatty)\n",
    "       - Homophony - different meaning same pronunciation (e.g, raise - raze - rays) \n",
    "       - Semantic - (e.g, cat - tabby)\n",
    "       - Sentence - (e.g, paraphrases)\n",
    "       - Document (e.g, two news stories on the same event)\n",
    "       - Cross-lingual - (e.g, Japan - Nihon)\n",
    "       \n",
    "       \n",
    "   - Morphological Similarity : Stemming\n",
    "       - reducing words to a base form called `stem`. (e.g, scanned->scan, indication->indicate)\n",
    "       - words with the same root (e.g, scan, scans, scanned(inflected), scanning, scanner, rescan, rescanned)\n",
    "       - Porter's stemming algorithm\n",
    "          - Rule based algorithm.\n",
    "          - The input is an individual word. The word is then transformed in a series of steps to its stem.\n",
    "          - Only works for English.\n",
    "          - e.g, computational->comput, computer->comput\n",
    "          - **`measure`** of a word is an indication of the number of syllables in it.\n",
    "              - Consonant(C), Vowel(V): (e.g, cat->cvc, cats->cvcc)\n",
    "              - [C] VCVC.. [V] or [C] (VC){k} [V] (`initial C` and `final V` optional)\n",
    "              - Example of Measures: (Count the occurrence of `VC` except initial(optional) C nor final V)\n",
    "                     k=0: I, AAA, CNN, TO, GLEE\n",
    "                     k=1: OR, EAST, BRICK, STREET, DOGMA\n",
    "                     k=2: OPAL, EASTERN, DOGMAS\n",
    "                     k=3: EASTERNMOST, DOGMATIC\n",
    "                     \n",
    "   - Spelling Similarity: Edit Distance\n",
    "      - Edit Operation (insertion / deletion / substitution / multiple edits)\n",
    "      - `Levenshtein Method` (DP, insertion / deletion / substitutions of cost 1)\n",
    "      \n",
    "** Preprocessing **\n",
    "   - Removing non-text\n",
    "   - Dealing with text encoding\n",
    "   - Sentence segmentation\n",
    "   - Noramlization - converting text to the same form.\n",
    "   - Stemming - merging words into same category(e.g, computer/computation)\n",
    "   - Morphological Analysis (e.g, car/cars)\n",
    "   - Capitalization\n",
    "   - Named entity extraction (e.g, USA/usa)\n",
    "   \n",
    "   - **Types vs. Tokens**\n",
    "      - Types: sequence of characters representing words\n",
    "      - Tokens: occurrence of a type\n",
    "      - (e.g, to be or not to be : 4 types, 6 tokens)\n",
    "   - **Tokenization** - how to split words among punctuation etc..\n",
    "   - Sentence Boundary Recognition - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "\n",
    "** Text Similiarity Continued.. **\n",
    "   - Synonyms\n",
    "      - Different words with simliar meanings.\n",
    "   - Polysemy - property of wrods to have multiple senses\n",
    "      - (e,g book - A literay work, A stack of pages, A record of business transactions, A record of bets, etc..)\n",
    "      - The same word can have multiple POS, each with different senses.\n",
    "      - Different senses have different frequencies, senses may overlap.\n",
    "\n",
    "** Other Semantic Relations **\n",
    "   - Antonymy(near opposites, e.g, raise-lower)\n",
    "   - Hypernymy(e.g, a deer is a hypernym for elk)\n",
    "   - Hyponymy(the inverse of Hypernymy)\n",
    "   - Membership Meronymy(e.g, a flock includes sheep(or birds))\n",
    "   - Part Meronymy(e.g, a table has legs)\n",
    "   \n",
    "   - Synset\n",
    "      - Semantic relations hold between **word sense**, not between words.\n",
    "         - antonym of hot -> mild ? cold\n",
    "         - immediate hypernym of bar -> room, musical notation, obstruction etc..\n",
    "      - The term `synset` is used to group together all synonyms of the same word.\n",
    "      - If the word is **`Polysemus`**, it maybe associated with multiple synsets.\n",
    "\n",
    "** Thesaurus-based Word Similarity Methods **\n",
    "   - Method1: Sim(v,w) = -pathlength(v,w)\n",
    "   - Method2: Sim(v,w) = - log pathlength(v,w)\n",
    "   - Method3(Phillip Resnik): Sim(v,w) = -log P(LCS(v,w))\n",
    "      - LCS = lowest common subsumer - lowest common ancestor of the path tree, e.g, ungulate <- deer/horse, deer <- deer/elk.\n",
    "   - Method4(Dekang Lin) - (nltk lin_similarity)\n",
    "      - (Information content)IC(c) = -log P(c)\n",
    "      - Sim(v,w) = 2 * log P(LCS(v,w)) / (log P(v) + log P(w))\n",
    "\n",
    "** Vector Space Model **\n",
    "   - Each term is a dimension, documents are linear combination of each terms.\n",
    "   - `Cosine distance`(angle) used to determine the similarity\n",
    "      - $\\sigma(D,Q) = \\frac{|D \\cap Q|} {\\sqrt{|D||Q|}} = \\frac{\\Sigma(d_i, q_i)} { \\sqrt{\\Sigma(d_i)^2} \\sqrt{\\Sigma(q_i)^2} } $\n",
    "   - max 1 with angle 0, min 0, since all the words are on `first quadrant`.\n",
    "   - `Jaccard Coefficient`:\n",
    "      - $\\sigma(D,Q) = \\frac{|D \\cap Q|} { |D \\cup Q | } $\n",
    "\n",
    "** Distributional Similarity **\n",
    "   - two words that appear in similar contexts are likely to be `semantically related`.\n",
    "   - the **context**:\n",
    "       - The word before/after the target word\n",
    "       - Any word within n words of the target word\n",
    "       - Any word within a `specific syntactic relationship` with the target word \n",
    "       - Any word within a same sentence/document\n",
    "       \n",
    "** Dimensionality Reduction **\n",
    "   - Documents are often about small number of topics.\n",
    "   - Problems with the Vector Space Model\n",
    "      - Polysemy(cosine distance comes out high and overestimates similarity)\n",
    "      - Synonyms(cosine distance comes out low and underestimates similarity)\n",
    "      - The matrix between words and sentences in general are `sparse`.\n",
    "      - Relatedness(e.g, doctor/patient/nurse/treatment)\n",
    "   - Most of the matrix(document to term) in NLP are non-square because number of vocabs and documents don't match.\n",
    "   - Document Term Matrix(D x W): \n",
    "       - raw matrix -> normalize -> Singular Value Decomposition -> pick a few largest eigenvalues(rank n) -> keep the eigenvectors corresponding to picked eigenvalues get reduced matrix.\n",
    "       - If A is a document to term matrix,\n",
    "           - A*A' = Document to Document matrix\n",
    "           - A'*A = Term to Term matrix\n",
    "           \n",
    "** NLP Tasks **\n",
    "   - Part of Speech Tagging\n",
    "   - Parsing - input -> syntactic representation\n",
    "   - Dependency Parsing - string -> dependency tree\n",
    "   - Information Extraction - string -> extract useful information(named entity, relationship etc..)\n",
    "   - Semantics\n",
    "       - First order logic\n",
    "       - Inference (e.g, if A is mother of B -> A is parent of B)\n",
    "       - Semantic Analysis\n",
    "   - Word Sense Disambiguation - which sense of the word is used? (I was at the bar today, bar?)\n",
    "   - Named Entity Recognition - identification of names, organizations etc..\n",
    "   - Semantic Role Labeling - label sentences using below roles\n",
    "       - V: verb\n",
    "       - A0: acceptor\n",
    "       - A1: thing accepted\n",
    "       - A2: accepted-from\n",
    "       - A3: attribute\n",
    "       - AM-MOD: modal\n",
    "       - AM-NEG: negation\n",
    "   - Coreference Resolution - identify expression referring to the same entity. do # of phrases refer to the same thing?\n",
    "       - anaphoric: the entity comes before pronoun. (e.g, Cynthia went to see her friend. She had an appointment made last week)\n",
    "       - cataphoric: the pronoun comes before entity. (e.g, Because he was sick, Michale stayed home on Friday.)\n",
    "   - Elipsis, Parallelism, Underspecification\n",
    "       (e.g, Chen speaks chinese. I don't, Santa gave Mary a book and Johhnny a toy.)\n",
    "   - Question/Answering\n",
    "   - Sentiment Analysis - recognize the object being discussed and determine the sentiments.\n",
    "   - Machine Translation\n",
    "   - Text Summarization\n",
    "   - Text to Speech\n",
    "   - Entrailment and Paraphrasing - Can you infer hypothesis from the text?\n",
    "       - e.g, `Text`: Google files for it's long awaited IPO | `Hypothesis`: Google goes public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876800984373\n",
      "0.531280836679\n"
     ]
    }
   ],
   "source": [
    "# Code section..\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "elephant = wn.synset('elephant.n.01')\n",
    "\n",
    "print dog.lin_similarity(cat, brown_ic)\n",
    "print dog.lin_similarity(elephant, brown_ic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
