{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1\n",
    "---\n",
    "** Basic NLP Pipeline**\n",
    "   - (U)nderstanding and (G)eneration\n",
    "   - Langauge -> (U) -> Computer -> (G) -> Language\n",
    "\n",
    "** Vocabulary**\n",
    "   - NLP(Natural Language Processing)\n",
    "   - CL(Computational Linguistics)\n",
    "   - IR(Information Retrieval)\n",
    "   - SP(Speech Processing)\n",
    "   - HLP(Human Language Technology)\n",
    "   - NLE(Natural Langauge Engineering)\n",
    "   - ML(Machine Learning)\n",
    "\n",
    "** Reasons for NLP Difficutiles**\n",
    "   - Syntax vs Semantics\n",
    "       - *Little a has Mary lamb. -> Syntactically incorrect.\n",
    "       - ?Colorless green ideas sleep furiously -> Syntactically well formed, Semantically(meaning) incorrect.\n",
    "   - Ambiguous words\n",
    "       - meaning: e.g, ball, board, plant\n",
    "       - part of speech: e.g, fly, rent, tape\n",
    "       - (multiple) pronunciation: e.g, address, resent, entrance, number, uninized\n",
    "       - Noun-noun phrases: (XY)Z vs X(YZ). e.g, science fiction writer, customer service representatives, state chess tournament.\n",
    "   - Types of ambibuity\n",
    "       - Morphologica: e.g, Joe is quite impossible. Joe is quite important.\n",
    "       - Phonetic: e.g, Joe's finger got number.\n",
    "       - Part of speech: e.g, Joe won the first round.\n",
    "       - Syntactic: e.g, Call joe a taxi.\n",
    "       - Pp attachment: e.g, Joe ate pizza with a fork.\n",
    "       - Sense: e.g, Joe took the bar exam.\n",
    "       - Modality: e.g, Joe may win the lottery.\n",
    "       - Subjectivity: e.g, Joe believes that stocks will rise.\n",
    "       - Cc(Coordinating Conjunction) attachement: e.g, Joe likes ripe apples **`and`** pears.\n",
    "       - Negation: e.g, Joe likes his pizza with no cheese and tomatoes.\n",
    "       - Referential: e.g, Joe yelled at Mike. He had broken the bike. (who's he?)\n",
    "       - Reflextive: e.g, John bought him a present.\n",
    "       - Ellipsis and parallelism: e.g, Joe gave Mike a beer and Jeremy a glass of wine.\n",
    "       - Metonymy: e.g, Boston called and left a message for Joe. (Boston not as city)\n",
    "       - Non-standard slang, novel words and usages: e.g, A360, spam, chillax\n",
    "       - Inconsistencie: e.g, pet spray, pet llama\n",
    "       - Typoes/Grammatical errors: e.g, Reciept, should of\n",
    "       - Parsing problems: e.g, Cup holder, Federal Reserve Board Chairman\n",
    "       - Complex sentences\n",
    "       - Counterfactual sentences: e.g, If you were ~\n",
    "       - Humor and sarcasm\n",
    "       - Implicature/inference/world knowledge: e,g I was late because my car broke down.(I imples, I own the car, car can break down..)\n",
    "       - Semantics vs. Pragmatics: e.g, Do you know the time?\n",
    "       - Synonyms and Paraphrases: e.g, The S&P500 **climbed** ~, it's **best close** since ~.\n",
    "\n",
    "**Linguistics knowledge**\n",
    "   - Constituents: e.g, Children eat pizza, They eat pizza.\n",
    "   - Collocations: e.g, Strong beer - *powerful beer, Big sister - *large sister.\n",
    "   - Knowledge about language:\n",
    "       - Phonetics and phonology - study of sounds\n",
    "       - Morphology: study of word components\n",
    "       - Syntax: study of sentence and phrases structure\n",
    "       - Lexical Sematics: study of the meaning of words\n",
    "       - Compositional semantics: how to combine words\n",
    "       - Pragmatics: how to accomplish goals\n",
    "       - Discourse conventios: how to deal with units larger than utterances\n",
    "\n",
    "**Theoretical Computer Science**\n",
    "   - Automata\n",
    "       - Deterministic and non-deterministic finite-state automata\n",
    "       - Push-down automata\n",
    "   - Grammars\n",
    "       - Regular grammars\n",
    "       - Context-free grammars\n",
    "       - Context-sensitive grammars\n",
    "   - Complexity\n",
    "   - Algorithms: Dynamic programming\n",
    "\n",
    "**Mathematical and Computational Tools**\n",
    "   - Language models\n",
    "   - Estimation methods\n",
    "   - Context-free grammars(CFG)\n",
    "   - Hidden Markov Models(HMM)\n",
    "   - Conditional Random Fields(CRF)\n",
    "   - Generative/discriminative models\n",
    "   - Maximum entroy models\n",
    "\n",
    "**Statistical Techniques**\n",
    "   - Vector space representation for WSD\n",
    "   - Noisy channel models for MT\n",
    "   - Graph-based Random walk methods for sentiment analysis\n",
    "\n",
    "** Artificial Intelligence**\n",
    "   - Logic, Agent, Planning, Constraint Satisfaction, Machine Learning.\n",
    "\n",
    "**`Cognates`** : a term in linguistic referring to words with common ancestry. (night, nuit, Nacht etc..)\n",
    "\n",
    "**Diversity of Languages**\n",
    "   - Articles: e.g, Russians don't have articles like *the, a* etc.\n",
    "   - Cases: e.g, *(Puer puellam vexat)*: Puer(Boy) is noun or normative, puellam(Girl) is subject, vexat(annoy) is verb. In latin the meaning of the words is retained regardless of word orders as long as verb comes the latest.\n",
    "   - Sound systems: e.g, Glottal stop - 'uh-oh'\n",
    "   - Social status: e.g, otousan, chichi\n",
    "   - Kinships: ways to refer to relatives.\n",
    "   \n",
    "**Languages Universals**\n",
    "   - unconditional: e.g, all languages have both verbs and nouns, all spoken languages have both consonants and vowels.\n",
    "   - conditional: \n",
    "       - e.g, if both subjects/objects are nouns, much more common to have subject preceding object.\n",
    "       - if inflection then derivation. e.g, inflection: sleep -> sleeps, derivation: drink -> drinkable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "---\n",
    "** Parts of Speech **\n",
    "   - Syntactic Categories\n",
    "      - Substitution test:\n",
    "         - Nathalie likes {black, Persian, tabby, small} cats.\n",
    "         - Single words that can be in same position. `Category: Adjective`\n",
    "      - Open(lexical) category:\n",
    "         - Can have words added as time goes: (e.g, No-fly-zone, twerk)\n",
    "      - Closed(functional) category:\n",
    "         - determiners or articles and prepositions(e.g, the, in)\n",
    "   - Parts of Speech\n",
    "      - Eight general types\n",
    "          - Noun (e.g, dog, tree, computer idea..)\n",
    "          - Pronoun (e.g, she, ourselves, mine..)\n",
    "          - Determiners\n",
    "              - Articles: (e.g, the, a)\n",
    "              - Demonstratives: (e.g, this, that)\n",
    "          - Adjective - describes properties\n",
    "          - Verb - actions, activities and states (e.g, throw, walk, have)\n",
    "              - intransitive (no direct object): The dog sleeps\n",
    "              - transitive (has direct object): The dog chased the cat.\n",
    "              - ditransitive (takes two objects): Mary gave the dog a bone.\n",
    "          - Adverb - happily, here, never\n",
    "          - Prepopsitions (e.g, of, through, in)\n",
    "          - Particles\n",
    "              - Phrasal verbs(e.g, the plane took off, take it off)\n",
    "          - Particles vs. Prepositions:\n",
    "              - She ran up a hill > Up a hill she ran (Preposition)\n",
    "              - She ran up a bill x Up a bill she ran (Particle)\n",
    "          - Coordinating conjunctions\n",
    "              - connects simliar parts of the sentence (e.g, and, or, but)\n",
    "          - Subordinating conjunctions\n",
    "              - connects different portions of the sentence that are not equal (e.g, if, because, that, although)\n",
    "          - Interjections (e.g, Ouch!)\n",
    "   \n",
    "   \n",
    "   - Parts of Speech Tags\n",
    "      > - NN - singular noun\n",
    "      > - IN - preposition\n",
    "      > - AT - article\n",
    "      > - NP - proper noun\n",
    "      > - JJ - adjective\n",
    "      > - , - comma\n",
    "      > - NNS - plural noun\n",
    "      > - CC - conjunction\n",
    "      > - RB - adverb\n",
    "      > - VB - un-inflected verb\n",
    "      > - VBN - verb + en (talen, looked (passive, perfect))\n",
    "      > - VBD - verb + ed (took, looked (past tense))\n",
    "      > - CS - subordinating conjunction\n",
    "\n",
    "** Morphology and Lexicon **\n",
    "   - Mental Lexicon - our mental process of interpreting texts (meaning? part of speech? pronunciation?)\n",
    "   - Derivational Morphology - how different forms of words are created from other words by adding different `affixes(prefix, suffix)`. (e.g, JJ <- V(drink) + able)\n",
    "   - Morphemes - the morphemes of words are individual units of morphological meaning.\n",
    "   - Inflectional Morphology - Tense, number, person, mood, aspect\n",
    "   - Morphological Analysis - takes a word and converts to morphological representation.\n",
    "       - sleeps = sleep(infinitive) + V(verb) + 3P(third person) + SG(singular)\n",
    "       - done = do(infinitive) + V(verb) + PP(past participle)\n",
    "\n",
    "** Semantics **\n",
    "   - Study of the meaning of words and sentences\n",
    "   - Lexical Semantics - meaning of individual words, relationship between the word pairs.\n",
    "   - Compositional Semantics - how to understand the meaning of a sentence based on the meaning of it's components.\n",
    "   \n",
    "** Pragmatics **\n",
    "\n",
    "** Text Similarity **\n",
    "   - Types of text similarity\n",
    "       - Morphological (e.g, respect - respectful)\n",
    "       - Spelling (e.g, theater - theatre)\n",
    "       - Synonymy - words with simliar meaning (e.g, talkative - chatty)\n",
    "       - Homophony - different meaning same pronunciation (e.g, raise - raze - rays) \n",
    "       - Semantic - (e.g, cat - tabby)\n",
    "       - Sentence - (e.g, paraphrases)\n",
    "       - Document (e.g, two news stories on the same event)\n",
    "       - Cross-lingual - (e.g, Japan - Nihon)\n",
    "       \n",
    "       \n",
    "   - Morphological Similarity : Stemming\n",
    "       - reducing words to a base form called `stem`. (e.g, scanned->scan, indication->indicate)\n",
    "       - words with the same root (e.g, scan, scans, scanned(inflected), scanning, scanner, rescan, rescanned)\n",
    "       - Porter's stemming algorithm\n",
    "          - Rule based algorithm.\n",
    "          - The input is an individual word. The word is then transformed in a series of steps to its stem.\n",
    "          - Only works for English.\n",
    "          - e.g, computational->comput, computer->comput\n",
    "          - **`measure`** of a word is an indication of the number of syllables in it.\n",
    "              - Consonant(C), Vowel(V): (e.g, cat->cvc, cats->cvcc)\n",
    "              - [C] VCVC.. [V] or [C] (VC){k} [V] (`initial C` and `final V` optional)\n",
    "              - Example of Measures: (Count the occurrence of `VC` except initial(optional) C nor final V)\n",
    "              >       k=0: I, AAA, CNN, TO, GLEE\n",
    "              >       k=1: OR, EAST, BRICK, STREET, DOGMA\n",
    "              >       k=2: OPAL, EASTERN, DOGMAS\n",
    "              >       k=3: EASTERNMOST, DOGMATIC\n",
    "                     \n",
    "   - Spelling Similarity: Edit Distance\n",
    "      - Edit Operation (insertion / deletion / substitution / multiple edits)\n",
    "      - `Levenshtein Method` (DP, insertion / deletion / substitutions of cost 1)\n",
    "      \n",
    "** Preprocessing **\n",
    "   - Removing non-text\n",
    "   - Dealing with text encoding\n",
    "   - Sentence segmentation\n",
    "   - Noramlization - converting text to the same form.\n",
    "   - Stemming - merging words into same category(e.g, computer/computation)\n",
    "   - Morphological Analysis (e.g, car/cars)\n",
    "   - Capitalization\n",
    "   - Named entity extraction (e.g, USA/usa)\n",
    "   \n",
    "   - **Types vs. Tokens**\n",
    "      - Types: sequence of characters representing words\n",
    "      - Tokens: occurrence of a type\n",
    "      - (e.g, to be or not to be : 4 types, 6 tokens)\n",
    "   - **Tokenization** - how to split words among punctuation etc..\n",
    "   - Sentence Boundary Recognition - Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "---\n",
    "** Text Similiarity Continued.. **\n",
    "---\n",
    "   - Synonyms\n",
    "      - Different words with simliar meanings.\n",
    "   - Polysemy - property of wrods to have multiple senses\n",
    "      - (e,g book - A literay work, A stack of pages, A record of business transactions, A record of bets, etc..)\n",
    "      - The same word can have multiple POS, each with different senses.\n",
    "      - Different senses have different frequencies, senses may overlap.\n",
    "\n",
    "** Other Semantic Relations **\n",
    "---\n",
    "   - Antonymy(near opposites, e.g, raise-lower)\n",
    "   - Hypernymy(e.g, a deer is a hypernym for elk)\n",
    "   - Hyponymy(the inverse of Hypernymy)\n",
    "   - Membership Meronymy(e.g, a flock includes sheep(or birds))\n",
    "   - Part Meronymy(e.g, a table has legs)\n",
    "   \n",
    "   - Synset\n",
    "      - Semantic relations hold between **word sense**, not between words.\n",
    "         - antonym of hot -> mild ? cold\n",
    "         - immediate hypernym of bar -> room, musical notation, obstruction etc..\n",
    "      - The term `synset` is used to group together all synonyms of the same word.\n",
    "      - If the word is **`Polysemus`**, it maybe associated with multiple synsets.\n",
    "\n",
    "** Thesaurus-based Word Similarity Methods **\n",
    "---\n",
    "   - Method1: Sim(v,w) = -pathlength(v,w)\n",
    "   - Method2: Sim(v,w) = - log pathlength(v,w)\n",
    "   - Method3(Phillip Resnik): Sim(v,w) = -log P(LCS(v,w))\n",
    "     > - LCS = lowest common subsumer - lowest common ancestor of the path tree, e.g, ungulate <- deer/horse, deer <- deer/elk.\n",
    "   - Method4(Dekang Lin) - (nltk lin_similarity)\n",
    "   > - (Information content)IC(c) = -log P(c)\n",
    "   > - Sim(v,w) = 2 * log P(LCS(v,w)) / (log P(v) + log P(w))\n",
    "\n",
    "** Vector Space Model **\n",
    "---\n",
    "   - Each term is a dimension, documents are linear combination of each terms.\n",
    "   - `Cosine distance`(angle) used to determine the similarity\n",
    "      >- $\\sigma(D,Q) = \\frac{|D \\cap Q|} {\\sqrt{|D||Q|}} = \\frac{\\Sigma(d_i, q_i)} { \\sqrt{\\Sigma(d_i)^2} \\sqrt{\\Sigma(q_i)^2} } $\n",
    "   - max 1 with angle 0, min 0, since all the words are on `first quadrant`.\n",
    "   - `Jaccard Coefficient`:\n",
    "      >- $\\sigma(D,Q) = \\frac{|D \\cap Q|} { |D \\cup Q | } $\n",
    "\n",
    "** Distributional Similarity **\n",
    "---\n",
    "   - two words that appear in similar contexts are likely to be `semantically related`.\n",
    "   - the **context**:\n",
    "       - The word before/after the target word\n",
    "       - Any word within n words of the target word\n",
    "       - Any word within a `specific syntactic relationship` with the target word \n",
    "       - Any word within a same sentence/document\n",
    "       \n",
    "** Dimensionality Reduction **\n",
    "---\n",
    "   - Documents are often about small number of topics.\n",
    "   - Problems with the Vector Space Model\n",
    "      - Polysemy(cosine distance comes out high and overestimates similarity)\n",
    "      - Synonyms(cosine distance comes out low and underestimates similarity)\n",
    "      - The matrix between words and sentences in general are `sparse`.\n",
    "      - Relatedness(e.g, doctor/patient/nurse/treatment)\n",
    "   - Most of the matrix(document to term) in NLP are non-square because number of vocabs and documents don't match.\n",
    "   - Document Term Matrix(D x W): \n",
    "       - raw matrix -> normalize -> Singular Value Decomposition -> pick a few largest eigenvalues(rank n) -> keep the eigenvectors corresponding to picked eigenvalues get reduced matrix.\n",
    "       - If A is a document to term matrix,\n",
    "           - A*A' = Document to Document matrix\n",
    "           - A'*A = Term to Term matrix\n",
    "           \n",
    "** NLP Tasks **\n",
    "---\n",
    "   - Part of Speech Tagging\n",
    "   - Parsing - input -> syntactic representation\n",
    "   - Dependency Parsing - string -> dependency tree\n",
    "   - Information Extraction - string -> extract useful information(named entity, relationship etc..)\n",
    "   - Semantics\n",
    "       - First order logic\n",
    "       - Inference (e.g, if A is mother of B -> A is parent of B)\n",
    "       - Semantic Analysis\n",
    "   - Word Sense Disambiguation - which sense of the word is used? (I was at the bar today, bar?)\n",
    "   - Named Entity Recognition - identification of names, organizations etc..\n",
    "   - Semantic Role Labeling - label sentences using below roles\n",
    "       - V: verb\n",
    "       - A0: acceptor\n",
    "       - A1: thing accepted\n",
    "       - A2: accepted-from\n",
    "       - A3: attribute\n",
    "       - AM-MOD: modal\n",
    "       - AM-NEG: negation\n",
    "   - Coreference Resolution - identify expression referring to the same entity. do # of phrases refer to the same thing?\n",
    "       - anaphoric: the entity comes before pronoun. (e.g, Cynthia went to see her friend. She had an appointment made last week)\n",
    "       - cataphoric: the pronoun comes before entity. (e.g, Because he was sick, Michale stayed home on Friday.)\n",
    "   - Elipsis, Parallelism, Underspecification\n",
    "       (e.g, Chen speaks chinese. I don't, Santa gave Mary a book and Johhnny a toy.)\n",
    "   - Question/Answering\n",
    "   - Sentiment Analysis - recognize the object being discussed and determine the sentiments.\n",
    "   - Machine Translation\n",
    "   - Text Summarization\n",
    "   - Text to Speech\n",
    "   - Entrailment and Paraphrasing - Can you infer hypothesis from the text?\n",
    "       - e.g, `Text`: Google files for it's long awaited IPO | `Hypothesis`: Google goes public."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4\n",
    "---\n",
    "** Syntax **\n",
    "---\n",
    "   - Helps understand the meaining of sentence.\n",
    "   - Context-free grammars are an appropriate representation for syntactic information.\n",
    "   - Dynamic Programming is needed for efficient parsing.\n",
    "   - Grammatical rules applying to group of words(not individual), forming sentence.\n",
    "   \n",
    "   - Constituents\n",
    "      - continuous / non-crossing(sharing constituents, one encompasses the other)/ each word is a constituent\n",
    "      - (word sequence)same constituents can be replaced by other member(of that constituent) and still form grammatically correct sentence.\n",
    "   - Constituent Tests\n",
    "        - Coordination test\n",
    "        - Pronoun test\n",
    "        - Question by repetition test\n",
    "        - Topicalization test\n",
    "        - Question test\n",
    "        - Semantic test\n",
    "        - Intuition test\n",
    "        \n",
    "        \n",
    "   - Sentences are generated by following syntactically correct grammars(e.g, **CFG**)\n",
    "       >- () - Optional categories\n",
    "       >- S -> NP VP \n",
    "       >- NP -> (DT) (JJ) N (PP)\n",
    "       >- VP -> V (NP) (PP)\n",
    "       >- PP -> P (NP)\n",
    "\n",
    "\n",
    "   - Converts `Word` into `Phrase` to denote with the sentence.\n",
    "   - Noun Phrases: whenever `N` is allowed in a sentence, follows below structure..\n",
    "       >- NP -> N | DT N | JJ N | DT JJ N -> (DT) (JJ) N\n",
    "       >- e.g, Cat The Cat, Small Cat, The Small Cat\n",
    "   - Verb Phrases\n",
    "       >- VP -> V (NP) (P) (NP)\n",
    "       >- e.g, Samantha ran, Samantha ran to the park, Samantha ran away, Samantha bought a cookie, Samantha bought a cookier for John.\n",
    "       \n",
    "** Parsing **\n",
    "---\n",
    "   - Parsing: associating tree structure to a sentence given a grammer(often a CFG).\n",
    "       - There maybe multiple tree structure or one or none. Choose the most appropriate one.\n",
    "   - Applications\n",
    "       - Grammer checking\n",
    "       - Question answering\n",
    "       - Machine translation\n",
    "       - Information extraction\n",
    "       - Speech generation/understanding\n",
    "       - Interpretation\n",
    "   - ** Context Free Grammers (CFG) **\n",
    "       - 4-tuple($N, \\Sigma, R, S$)\n",
    "           - N: non-terminal symbols\n",
    "           - $\\Sigma$ : terminal symbols (disjoint from N)\n",
    "           - R: rules ($A(nonterminals)$ -> $\\beta$), $\\beta$ is a string from $\\Sigma \\cup N)^*$\n",
    "           - S: specific designated start symbol in N\n",
    "       - Example grammar\n",
    "           >- Headed Constituents(**bold**) - one component(**head**) is more important than the other.\n",
    "           >- S -> NP VP \n",
    "           >- NP -> DT **N** | NP PP \n",
    "           >- PP -> **PRP** NP\n",
    "           >- VP -> **V** NP | VP PP\n",
    "           >- DT -> 'a' | 'the'\n",
    "           >- N -> 'child' | 'cake' | 'fork'\n",
    "           >- PRP -> 'with' | 'to'\n",
    "           >- V -> 'saw' | 'ate'\n",
    "\n",
    "   - ** Phrase-structure Grammers **\n",
    "       - Sentences are not just bags of words\n",
    "           - Alice bought bob flowers vs Bob bought Alice flowers\n",
    "       - Context-free view of language\n",
    "           - A prepositional phrase looks the same whether iti s part of the subject NP or part of the VP\n",
    "       - Auxiliary verbs\n",
    "       - ADD MORE NOTES HERE LATER...................................\n",
    "       \n",
    "       \n",
    "   - **Leftmost Derivation** - parse the sentence by always expanding the left-most unexpanded non-terminals.\n",
    "   \n",
    "** Classic Parsing Methods **\n",
    "---\n",
    "   - Parsing as Search problem\n",
    "   - Two approaches\n",
    "       - **Top-down**: start from the `S` level, expand the tree structure until reaching input string.\n",
    "           - downside: explores options that don't match the `full sentence`.\n",
    "       - **Bottom-up**: start from the sentence, combine adjacent words into constituensts and combine until reaching the `S` level the top.\n",
    "           - downside: explores options that won't lead to a `full parse`.\n",
    "           >- e.g, the child ate the cake with the fork\n",
    "           >- ---\n",
    "           >- **Binary Grammers** - see CNF rules below\n",
    "           >- ---          \n",
    "           >- **Two non-terminals**\n",
    "           >- S -> NP VP \n",
    "           >- NP -> DT N | NP PP\n",
    "           >- PP -> PRP NP\n",
    "           >- VP -> V NP | VP PP\n",
    "           >- ---\n",
    "           >- ** Lexicons ** - turning DT,N,PRP,V into **terminals**.\n",
    "           >- DT -> 'a' | 'the'\n",
    "           >- N -> 'child' | 'cake' | 'fork'\n",
    "           >- PRP -> 'with' | 'to'\n",
    "           >- V -> 'saw' | 'ate'   \n",
    "\n",
    "   - **Cocke-Kasami-Younger** parser - dynamic programming based parser\n",
    "        - Bottom-up parser, requires a normalized(binarized) grammar.\n",
    "        - Space: $O(n^2)$ cells in the table, each cell requires a linear lookup, Time: $O(n^3)$\n",
    "        - Issues: Weak equivalence only\n",
    "            - Same language, different structure.\n",
    "            - Converted CNF's final parse tree doesn't match the original grammar.\n",
    "            - Can be converted back.\n",
    "        - Issues: Syntactic Ambiguities\n",
    "            - Has no way to perform syntactic disambiguation, has to use probaibilities or external procedure.\n",
    "\n",
    "   - **Earley parser** - also dynamic programming based.\n",
    "        - Top-down, doesn't require binary grammar.\n",
    "        - No need to convert grammar into CNF. Left to Right parsing.\n",
    "           \n",
    "   - **Chomsky Normal Form(CNF)**\n",
    "        - All rules have to be in binary form: (converts non-binary(hybrid, n-ary, unary) grammer into binary)\n",
    "            - X -> Y Z (non-terminal going to two non-terminals)\n",
    "            - X -> W (non-terminal going to a terminal)\n",
    "\n",
    "\n",
    "   - Shift-reduce Parsing\n",
    "       - Bottom-up parser\n",
    "       - Shift operation - push the next word on to stack.\n",
    "       - Reduce operation - if the top n words of the stack match the **`RHS`** of a production, replaced with **`LHS`** of that production.  \n",
    "       - Stop when **`S`** reached.\n",
    "       >- e.g, [* the child ate the cake]\n",
    "       >- S ['the' * child ate the cake] - push 'the' to stack.\n",
    "       >- R [ DT * child ate the cake] - replace 'the' with DT.\n",
    "       >- S [ DT 'child' * ate the cake] - push 'child' to the stack.\n",
    "       >- R [ DT N * ate the cake] - replace 'child' with DT,\n",
    "       >- R [ NP * ate the cake] - reduce DT N -> NP\n",
    "       >- S [ NP 'ate' * the cake] - push 'ate' to stack.\n",
    "       >- R [ NP V * the cake] - replace 'ate' with V.\n",
    "       >- S [ NP V * 'the' cake] - push 'the' to stack.\n",
    "       >- R [ NP V DT * cake] - replace 'the' with DT.\n",
    "       >- S [ NP V DT 'cake' * ] - push 'cake' to stack.\n",
    "       >- R [ NP V DT N * ] - replace 'cake' with N.\n",
    "       >- R [ NP V NP * ] - reduce DT N -> NP.\n",
    "       >- R [ NP VP * ] - reduce V NP -> VP.\n",
    "       >- R [ S * ] - reduce NP VP -> S(done).\n",
    "       >- **(S (NP (DT the) (N child)) (VP (V ate) (NP (DT the) (N cake))))**\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "---\n",
    "** Prepositional Phrase Attachment **\n",
    "---\n",
    "---\n",
    "   - Prepositional (e.g, with, as, of) phrases can modify either closest Noun or Verb before that Noun.\n",
    "   - **`Def`**: Which POS to attach Preposition?\n",
    "       - High(verbal) attachment: **join** board **as director** (attaches nearest verb, way in which person joined the board)\n",
    "       - Low(nominal) attachment: is **`chairman`** **of Elsevier** (modifies chairman)\n",
    "       - Example:\n",
    "       >- Lucy's plane leaves Destroit **on Monday** - high (modifies leaves)\n",
    "       >- Jenna met Mike **at the concert**. - high (modifies meet)\n",
    "       >- This painting must cost millions **of dollars** - low(modifies millions)\n",
    "       >- Alicia ate spaghetti **from Italy.** - low(spaghetti)\n",
    "       >- Alicia ate spaghetti ** with meatballs.** - low(spaghetti)\n",
    "       >- Alicia ate spaghetti **with a fork.** - high(ate)\n",
    "       >- Alicia ate spaghetti **with Justin.** - high(ate) > `Alicia didn't eat Spaghetti and Justin together.`\n",
    "       >- Alicia ate spaghetti **with delight.** - high(ate)\n",
    "       >- Alicia ate spaghetti **on Friday.** - high(Alicia)\n",
    "   - In parse tree perspective, the phrase is at the **same level** as the verb/noun it modifies.\n",
    "   \n",
    "   - Binary Classification Problem\n",
    "       - Represent prepositional phrase instance by four features(tuples) - enough to determine the attachment.\n",
    "           1. (Verb/Noun before Preposition)\n",
    "           3. (Noun after Preposition)\n",
    "           4. (Preposition)\n",
    "           \n",
    "   - Use Supervised Learning to Evaluate\n",
    "\n",
    "** Statistical Parsing **\n",
    "---\n",
    "---\n",
    "   - ** Probbabilistic Context Free Grammers (CFG) **\n",
    "       - 4-tuple($N, \\Sigma, R, S$)\n",
    "           - N: non-terminal symbols\n",
    "           - $\\Sigma$ : terminal symbols (disjoint from N)\n",
    "           - R: rules ($A(nonterminals) [p]$ -> $\\beta$), \n",
    "               - $\\beta$ is a string from ($\\Sigma \\cup N)^*$\n",
    "               - p = probability $P(\\beta | A)$\n",
    "           - S: specific designated start symbol in N\n",
    "       - Probabilities from same LHS should add up to 1.\n",
    "       - Example\n",
    "           >- S -> NP VP [p0=1] \n",
    "           >- NP -> DT N [p1]   ** p1 + p2 = 1 **\n",
    "           >- NP -> NP PP [p2]\n",
    "           >- PP -> PRP NP [p3=1]\n",
    "           >- VP -> V NP [p4]   ** p4 + p5 = 1 **\n",
    "           >- VP -> VP PP [p5]\n",
    "           >- DT -> 'a' etc..\n",
    "           >- DT -> 'the'           \n",
    "           >- N -> 'child'\n",
    "           >- N -> 'cake'\n",
    "           >- N -> 'fork'\n",
    "           >- PRP -> 'with'\n",
    "           >- PRP -> 'to'\n",
    "           >- V -> 'saw'\n",
    "           >- V -> 'ate'\n",
    "   - Probabilities of a Parse Tree\n",
    "       - $ p(t) = \\Pi_{i=1}^np(\\alpha_i \\to \\beta_i) $\n",
    "   - The most likely parse: \n",
    "       - $argmax_{t \\in T(s)} p(t)$\n",
    "   - Probabilities of a Sentence is the sum of the probabilities of all underlying parses.\n",
    "   - Given a grammar G and a sentence S, T(s) = all possible parse trees.\n",
    "       - Task1: find the T(S) with maximum probability p(t).\n",
    "       - Task2: find P(S) as the sum of all possible tree probabilities p(t).\n",
    "   - Probabilities can be learned from a training corpus.\n",
    "   - Maximum Likelihood Estimates\n",
    "       - $P_{ML} (\\alpha \\to \\beta) = Count(\\alpha \\to \\beta) / Count(\\alpha)$\n",
    "       - $P_{ML} (S \\to NP \\: VP) = Count(S \\to NP \\: VP) / Count(S)$\n",
    "   - Both CKY / Earley methods can be used.\n",
    "   \n",
    "** Lexicalized Parsing **\n",
    "---\n",
    "---\n",
    "   - Limitation of PCFGs\n",
    "       - The probabilities don't depend on the specific words.\n",
    "           - e.g, `give` someone something vs. `see` something. \n",
    "       - Not possible to disambiguate sentences based on semantic information.\n",
    "           - e.g, eat pizza with `pepperoni`(low) vs. `eat pizza with fork`(high). Hard to figure out what each word would attach to(high vs low).\n",
    "   - So use Lexicalized grammers.\n",
    "        - Use the `head` of the phrase as an additional information. e.g, VP[ate] -> V[ate]\n",
    "        - Start from the lowest level of Parse tree(terminal symbols/words), extract heads of every constituents recursively until reaching top sentence S.\n",
    "   - Collins Parser\n",
    "   - Issues\n",
    "        - Sparse training data\n",
    "        - Combinatorial explosition\n",
    "   - Discriminative Reranking\n",
    "       - Among the possible parses from PCFG, incorporate additional information such as..\n",
    "           - Parse tree depth.\n",
    "           - Left attachment vs. Right attachment.\n",
    "           - Discourse structure.\n",
    "           - Sentence consistency\n",
    "           - Other stages of NLU pipelines (POS sequence, Speech Recognition constraints)\n",
    "           \n",
    "** Dependency Parsing **\n",
    "---\n",
    "---\n",
    "   - The basic observation behind **constituency** is that groups of words may act as one unit. (e.g, noun phrase, prepositional phrase)\n",
    "   - The basic observation behind **dependency** is that words have grammatical functions with respect to other words in the sentene. (e.g. subject, modifier)\n",
    "   - Non constituent parsing.\n",
    "   - Dependency Structure\n",
    "      - e.g, blue(modifier, dependent, child, subordinate) <- house(head, governor, root)\n",
    "   - Dependency Grammars\n",
    "      - Lexical/syntactic dependencies between words.\n",
    "      - The top-level predicate of a sentene is the root.\n",
    "      - Simpler to parse than context-free grammars.\n",
    "      - Particularly useful for free word order languages.\n",
    "   - How to identify Heads (H=head, M=modifier)\n",
    "      - H determines the syntactic/semantic category of the construct.\n",
    "      - H is required; M may be skipped.\n",
    "      - Fixed linear position of M with respect to H. (e.g, adjective can modify noun next to it)\n",
    "   - Projectivity / Non-projectivity(dependency crossing)\n",
    "   - Equivalent to Maximum Spanning Tree problem.\n",
    "   - MaltParser (Arc-eager parser)\n",
    "       - Components: stack, buffer, dependencies(arcs)\n",
    "       - Reduce operation combine an element from the stack and one from buffer\n",
    "       - Operations: shift, reduce, left-arc, right-arc\n",
    "       - Example\n",
    "           >- People want to be free\n",
    "           >- [ROOT]    [People, want, to, be, free]     \n",
    "           >- Shift [ROOT, People] [want, to, be, free]\n",
    "           >- $LA_{nsubj}$ [ROOT] [want, to, be, free] $A_{1} = {nsubj(want, people)}$\n",
    "           >- $RA_{root}$ [ROOT, want] [to, be, free] $A_{2} = A_{1}$ $ \\cup \\> {root(ROOT, want)}$\n",
    "       - Classifier chooses next action, no search.\n",
    "       - Final arc list is the returned dependency tree.\n",
    "   - Dependency Kernel - determines how similiar two sentences are based on dependency parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5\n",
    "---\n",
    "** Bayes Theorem **\n",
    "---\n",
    "---\n",
    "   - **`Example`**:\n",
    "       >- $ P(A,B) = P(A) * P(B|A) = P(B) * P(A|B) $\n",
    "       >- $ P(B|A) = \\frac{P(B) * P(A|B)} { P(A) } $\n",
    "       >- $ P(disease | positive) = \\frac{P(positive|disease) * P(disease)} {P(positive)} $\n",
    "       >- $ P(\\neg disease | positive) = \\frac{P(positive|\\neg disease) * P(\\neg disease)} {P(positive)} $\n",
    "       >- $ \\frac {P(disease | positive) } {P(\\neg diseas | positive) } = \n",
    "           \\frac{P(positive|disease) * P(disease)} {P(positive|\\neg disease) * P(\\neg disease)} $\n",
    "       >- $ \\frac {P(disease | positive) } {P(\\neg disease | positive) } = (0.95 * 0.001) / (0.05 * 0.999) = 0.019$\n",
    "       >- $ P(disease | positive) + P(\\neg disease | positive) = 1 $\n",
    "       >- $ P(diseaese | positive) \\approx 0.02 $\n",
    "       >- $P(disease)$ is called **prior** probability.\n",
    "       >- $P(disease|positive)$ is called **posterior** probability.\n",
    "\n",
    "** Language Modeling **\n",
    "---\n",
    "---\n",
    "   - ** Probabilistic Language Models **\n",
    "       - Assign a probaiblity to a sentence. Which sentence interpretation is more likely??\n",
    "           - P(S) = P(W1, W2, W3... , Wn)\n",
    "       - The sum of the probabilities of all possible sentences = 1\n",
    "       - Predicting the next word - P(Wn| W1, W2, ..., Wn-1)\n",
    "   - Uses: speech recognition, Text generation, Spelling correction, Machine translation, OCR, Summarization, Document Classification.\n",
    "   \n",
    "   \n",
    "   - ** Probability of a sentence**\n",
    "       - P(S) = P(W1,W2,...Wn) = P(W1) P(W2|W1) P(W3|W1,W2) ... P(Wn|W1,W2,...Wn-1)\n",
    "       - Chain rule doesn't lose information.\n",
    "       \n",
    "\n",
    "   - ** N-gram Models **\n",
    "       - Predict the probability of a word based on the words before\n",
    "       - Markov assumption - probability of a word is dependent on recent one or two(etc) word.\n",
    "           - P(\"musical | I would like two tickets for the\") = P(\"musical | the\") (**Bigram**) or P(\"musical | for the\") (**Trigram**)\n",
    "       - Unigram, Bigram, Trigram etc.\n",
    "       \n",
    "       - **Maximum Likelihood Estimates**\n",
    "           >- Unigram: P(Wi) = C(Wi) / V -> P(pizza) = 700 / 1000000 (doesn't take word order in account)\n",
    "           >- Bigram: P(Wi|Wi-1) = C(Wi-1, Wi) / C(Wi-1) ->\"with\" appears 1000 times, \"with Spinach\" appears 6 times, MLE for P('spinash|with) = 6/1000 = 0.006\n",
    "           >- Example:\n",
    "               - P(\"Elizabeth\") = 0.1\n",
    "               - P(\"looked | Elizabeth\") = 0.2\n",
    "               - P(\"at | looked\") = 0.15\n",
    "               - P(\"Darcy | at\") = 0.25\n",
    "               - Bigram Prob(\"Elizabeth looked at Darcy\") = 0.1 * 0.2 * 0.15 * 0.25\n",
    "               - Unigram Prob(\"Elizabeth looked at Darcy\") = P(\"Elizabeth\") * P(\"looked\") * P(\"at\") * P(\"Darcy\")\n",
    "               \n",
    "   - ** Generative Models **\n",
    "       - Unigram: generate a word, continue until you generate <\\S>\n",
    "       - Bigram: generate S, generate a word, generate next one based on previous word until you generate <\\S>\n",
    "       \n",
    "\n",
    "   - ** Smoothing(Regularization) **\n",
    "       - **Issue**: If the vocabulary of size |V| = 1M, too many parameters to estimate, MLE assining 0 to unseen data is possible but unacceptable. Bigram, Trigram parameters even more..\n",
    "       \n",
    "       - Assign arbitrary value to **`unseen`** data.\n",
    "           >- Distributing some of the probability mass to allow for novel(new) events(data).\n",
    "           >- **`Laplace`** smoothing(Add 1)\n",
    "           >- Bigram: $P(W_i|W_{i-1}) = (C(W_{i-1},W_i) + 1) / (C(W_{i-1}) + V) $\n",
    "       - Advanced smoothing\n",
    "           - Good Turing\n",
    "              >- Predict the probabilities of **`unseen`** events based on the probabilities of **`seen`** events.\n",
    "              >- 1. Calculate the probabilities of all seen events(words)\n",
    "              >- 2.. then recompute counts: $C* = (C+1) N_{C+1} / N_C$\n",
    "              >- $N_C$ is the # of words each occuring **C** times.\n",
    "              >- $N_0$ is the total # of n-grams in the corpus.\n",
    "              >- For unseen words, use $N_1 / N$\n",
    "       - Backoff \n",
    "           - going back to lower-order n-gram model if the higher-order model is `sparse`. (e.g. use trigram if available, otherwise we use bigram or unigram. Sometimes `less context` is a good thing.\n",
    "       - Interpolation\n",
    "           - If $P(Wi|W_{i-1}, W_{i-2})$ is `sparse` (`unavailable`):\n",
    "               - Use $\\lambda_1 P'(W_{i}|W_{i-1},W_{i-2}) + \\lambda_2 P'(W_{i}|W_{i-1}) + \\lambda_3 P'(W_i)$\n",
    "               \n",
    "               \n",
    "   - ** Evaluation **\n",
    "      - Intrinsic Method\n",
    "          - Perplexity: how well the model fits the data\n",
    "              >- Average branching factor in predicintg the next word\n",
    "              >- Lower is better\n",
    "              >- N = number of words\n",
    "              >- $ Per = \\sqrt[N] {\\frac {1} {P(W_1,W_2...W_N)}} $\n",
    "              >- e.g. $If P(W_i) = 1/k, Per = (1/k)^{N*1/N} = k$\n",
    "              >- i.e. Picking a number between 1 and 10, perplexity = 10, Alphabet = 26\n",
    "\n",
    "\n",
    "** Word Sense Disambiguation **\n",
    "---\n",
    "---\n",
    "   - Given a word and its context, figure out a sense among muptiple possilble senses.\n",
    "   - Polysemy : words having multiple sense\n",
    "   - Dictionary Method:\n",
    "       - Match senteces to dictionary definitions\n",
    "       - Find the pair of meaninigs that have the most overlapping definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876800984373\n",
      "0.531280836679\n"
     ]
    }
   ],
   "source": [
    "# Code section...\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "elephant = wn.synset('elephant.n.01')\n",
    "\n",
    "print dog.lin_similarity(cat, brown_ic)\n",
    "print dog.lin_similarity(elephant, brown_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def editDistance(sentence_1, sentence_2):\n",
    "    ''' calculates the edit distance between two parameter sentences. '''\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
